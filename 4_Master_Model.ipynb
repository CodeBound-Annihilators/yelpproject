{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import folium\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire the Merged.csv of the health and Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('merged.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2409 entries, 0 to 2408\n",
      "Data columns (total 29 columns):\n",
      "Unnamed: 0              2409 non-null int64\n",
      "inspection_date         2409 non-null object\n",
      "inspector               2409 non-null object\n",
      "number_of_violations    2409 non-null int64\n",
      "violations              2409 non-null object\n",
      "zip_code                2409 non-null int64\n",
      "house_numbers           2409 non-null int64\n",
      "categories              2409 non-null object\n",
      "transactions            2409 non-null object\n",
      "distance                2409 non-null float64\n",
      "review_count            2409 non-null float64\n",
      "longitude               2409 non-null float64\n",
      "latitude                2409 non-null float64\n",
      "name                    2409 non-null object\n",
      "sector                  2409 non-null int64\n",
      "district                2409 non-null object\n",
      "total_score             2409 non-null int64\n",
      "rating                  2409 non-null float64\n",
      "price                   2409 non-null object\n",
      "establishment_x         2409 non-null object\n",
      "establishment_y         2409 non-null object\n",
      "address_x               2409 non-null object\n",
      "address_y               2409 non-null object\n",
      "trimmed_name_x          2409 non-null object\n",
      "trimmed_name_y          2409 non-null object\n",
      "clean_address_x         2409 non-null object\n",
      "clean_address_y         2409 non-null object\n",
      "address_distance        2409 non-null int64\n",
      "name_distance           2409 non-null int64\n",
      "dtypes: float64(5), int64(8), object(16)\n",
      "memory usage: 545.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(df)\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>number_of_violations</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_numbers</th>\n",
       "      <th>distance</th>\n",
       "      <th>review_count</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>sector</th>\n",
       "      <th>total_score</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1204.000000</td>\n",
       "      <td>4.989622</td>\n",
       "      <td>78220.360731</td>\n",
       "      <td>4494.122042</td>\n",
       "      <td>7806.578807</td>\n",
       "      <td>161.892902</td>\n",
       "      <td>-98.514704</td>\n",
       "      <td>29.486358</td>\n",
       "      <td>16.587796</td>\n",
       "      <td>94.044832</td>\n",
       "      <td>3.574720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>695.562722</td>\n",
       "      <td>4.708035</td>\n",
       "      <td>14.884181</td>\n",
       "      <td>4491.037788</td>\n",
       "      <td>3305.930381</td>\n",
       "      <td>264.744464</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>0.055306</td>\n",
       "      <td>9.608700</td>\n",
       "      <td>5.482347</td>\n",
       "      <td>0.769284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78201.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>811.199667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-98.708442</td>\n",
       "      <td>29.354318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>602.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>78209.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>5840.653743</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>-98.564331</td>\n",
       "      <td>29.430632</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1204.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>78216.000000</td>\n",
       "      <td>2727.000000</td>\n",
       "      <td>7940.300340</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>-98.499740</td>\n",
       "      <td>29.486788</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1806.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>78230.000000</td>\n",
       "      <td>7400.000000</td>\n",
       "      <td>9571.434425</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>-98.480582</td>\n",
       "      <td>29.526893</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2408.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>78259.000000</td>\n",
       "      <td>22211.000000</td>\n",
       "      <td>20222.717722</td>\n",
       "      <td>2661.000000</td>\n",
       "      <td>-98.397780</td>\n",
       "      <td>29.661520</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  number_of_violations      zip_code  house_numbers  \\\n",
       "count  2409.000000           2409.000000   2409.000000    2409.000000   \n",
       "mean   1204.000000              4.989622  78220.360731    4494.122042   \n",
       "std     695.562722              4.708035     14.884181    4491.037788   \n",
       "min       0.000000              0.000000  78201.000000       1.000000   \n",
       "25%     602.000000              2.000000  78209.000000     849.000000   \n",
       "50%    1204.000000              4.000000  78216.000000    2727.000000   \n",
       "75%    1806.000000              7.000000  78230.000000    7400.000000   \n",
       "max    2408.000000             50.000000  78259.000000   22211.000000   \n",
       "\n",
       "           distance  review_count    longitude     latitude       sector  \\\n",
       "count   2409.000000   2409.000000  2409.000000  2409.000000  2409.000000   \n",
       "mean    7806.578807    161.892902   -98.514704    29.486358    16.587796   \n",
       "std     3305.930381    264.744464     0.059607     0.055306     9.608700   \n",
       "min      811.199667      1.000000   -98.708442    29.354318     1.000000   \n",
       "25%     5840.653743     22.000000   -98.564331    29.430632     8.000000   \n",
       "50%     7940.300340     69.000000   -98.499740    29.486788    17.000000   \n",
       "75%     9571.434425    186.000000   -98.480582    29.526893    22.000000   \n",
       "max    20222.717722   2661.000000   -98.397780    29.661520    35.000000   \n",
       "\n",
       "       total_score       rating  \n",
       "count  2409.000000  2409.000000  \n",
       "mean     94.044832     3.574720  \n",
       "std       5.482347     0.769284  \n",
       "min      56.000000     1.000000  \n",
       "25%      91.000000     3.000000  \n",
       "50%      95.000000     3.500000  \n",
       "75%      98.000000     4.000000  \n",
       "max     100.000000     5.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping redundant and unneccesary columns\n",
    "\n",
    "df= df.drop(df[['transactions', 'price', 'establishment_x', 'establishment_y', 'address_x', 'address_y', 'trimmed_name_x', 'trimmed_name_y', 'clean_address_x', 'clean_address_y', 'address_distance', 'name_distance']], axis=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2409 entries, 0 to 2408\n",
      "Data columns (total 17 columns):\n",
      "Unnamed: 0              2409 non-null int64\n",
      "inspection_date         2409 non-null object\n",
      "inspector               2409 non-null object\n",
      "number_of_violations    2409 non-null int64\n",
      "violations              2409 non-null object\n",
      "zip_code                2409 non-null int64\n",
      "house_numbers           2409 non-null int64\n",
      "categories              2409 non-null object\n",
      "distance                2409 non-null float64\n",
      "review_count            2409 non-null float64\n",
      "longitude               2409 non-null float64\n",
      "latitude                2409 non-null float64\n",
      "name                    2409 non-null object\n",
      "sector                  2409 non-null int64\n",
      "district                2409 non-null object\n",
      "total_score             2409 non-null int64\n",
      "rating                  2409 non-null float64\n",
      "dtypes: float64(5), int64(6), object(6)\n",
      "memory usage: 320.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Dropped all establishments with less than 22 reviews \n",
    "# df=  df[df['review_count'] >= 22] \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping Health Scores into bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped health scores into 4 groups\n",
    "health_scores= {'health_scores' : []}\n",
    "for x in df['total_score']:\n",
    "#     print(x)\n",
    "    if x > 99:\n",
    "        health_scores['health_scores'].append('1')\n",
    "    elif x>=96:\n",
    "        health_scores['health_scores'].append('2')\n",
    "    elif x >=92:\n",
    "        health_scores['health_scores'].append('3')\n",
    "    else :\n",
    "        health_scores['health_scores'].append('4')\n",
    "#df\n",
    "df['health_scores']= health_scores['health_scores']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the distribution of health scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    697\n",
       "4    657\n",
       "3    608\n",
       "1    447\n",
       "Name: health_scores, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['health_scores'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lauren Schumacher     194\n",
       "Jacob Johanson        159\n",
       "RYAN DAVIS            153\n",
       "Jeffrey Carrizales    148\n",
       "Sumner Bumgardner     127\n",
       "Diana Garcia          117\n",
       "Cicily Martinez       116\n",
       "Bamba Njie            109\n",
       "Bernard Capdeboscq    105\n",
       "Valerie Suarez        104\n",
       "Benito Zuniga          97\n",
       "Deborah Liu            96\n",
       "Nathan Balfour         90\n",
       "Raul Jimenez           87\n",
       "Daisy Zamora           82\n",
       "Debra Hernandez        59\n",
       "MICHELLE MORENO        55\n",
       "Mario Cavazos          54\n",
       "Kassandra Aguilar      53\n",
       "Amanda Cantu           52\n",
       "John Payelle           48\n",
       "William Hudson         43\n",
       "Erica Arreola          42\n",
       "William Emminger       37\n",
       "Kathleen Prenzler      34\n",
       "Adan Zamora            24\n",
       "Monica Caballero       22\n",
       "Sean Gilbert           20\n",
       "Kacie Patrick          20\n",
       "Fermin Garza           18\n",
       "Joe Mokry              15\n",
       "Juanicia Page          10\n",
       "Victoria Paredes        9\n",
       "Daniel Guzman           4\n",
       "Maurico Ripley          3\n",
       "Erica Llanas            2\n",
       "Rebecca Vera            1\n",
       "Name: inspector, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode for the inspectors\n",
    "df['inspector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping inspectors that have not copmpleted AT LEAST 2 inspections\n",
    "vdf = pd.DataFrame(df['inspector'].value_counts())\n",
    "vdf['check'] = vdf['inspector'] > 1\n",
    "over_20 = list(vdf.loc[vdf['check'], :].reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2408 entries, 0 to 2408\n",
      "Data columns (total 17 columns):\n",
      "inspection_date         2408 non-null object\n",
      "inspector               2408 non-null object\n",
      "number_of_violations    2408 non-null int64\n",
      "violations              2408 non-null object\n",
      "zip_code                2408 non-null int64\n",
      "house_numbers           2408 non-null int64\n",
      "categories              2408 non-null object\n",
      "distance                2408 non-null float64\n",
      "review_count            2408 non-null float64\n",
      "longitude               2408 non-null float64\n",
      "latitude                2408 non-null float64\n",
      "name                    2408 non-null object\n",
      "sector                  2408 non-null int64\n",
      "district                2408 non-null object\n",
      "total_score             2408 non-null int64\n",
      "rating                  2408 non-null float64\n",
      "health_scores           2408 non-null object\n",
      "dtypes: float64(5), int64(5), object(7)\n",
      "memory usage: 338.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df['check'] = df['inspector'].isin(over_20)\n",
    "new_df = df.loc[df['check'], :]\n",
    "new_df = new_df.drop(columns = ['check', 'Unnamed: 0'])\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding sector data to add geographical reference to inspector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Entries is 2408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the inspector column for modeling.\n",
    "label_enc= LabelEncoder()\n",
    "new_df[\"sector_encode\"] = label_enc.fit_transform(new_df.sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHot Encoding\n",
    "one_enc = OneHotEncoder()\n",
    "Y = one_enc.fit_transform(new_df.sector_encode.values.reshape(-1,1)).toarray()\n",
    "# df_array = np.array(new_long_df.encoded).reshape(len(new_long_df.encoded),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the encoded data to the main Df\n",
    "# elist = [X,Y,Z]\n",
    "dfOneHot = pd.DataFrame(Y, columns = [\"sector_\"+str(int(i)) for i in range(Y.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.reset_index()\n",
    "new_df = new_df.reset_index()\n",
    "new_df['index']= new_df['level_0']\n",
    "new_df = new_df.drop(columns = ['level_0'])\n",
    "dfOneHot = dfOneHot.reset_index()\n",
    "enc_df=new_df.join(dfOneHot, on = 'index', lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decision tree including number of review, total violations, yelp score, and inspector\n",
    "#training / test split\n",
    "X= enc_df.drop(columns=[ 'index_left', 'index_right', 'inspection_date','longitude', 'latitude',  'inspector', 'number_of_violations','violations', 'zip_code', 'house_numbers', 'categories', 'distance', 'name', 'sector', 'district', 'health_scores', 'total_score', 'sector_encode'])\n",
    "y= enc_df['health_scores']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 42, stratify=enc_df.health_scores)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "\n",
    "#Create the Decision Tree Object\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state= 42, min_samples_split= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model to the training data\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate health group\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of a health group\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy: number of correct predictions over the number of total instances that have been evaluated.\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Model\n",
    "\n",
    "#Compute the accuracy of the model when run on the test data\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the accuracy with chi square\n",
    "\n",
    "#Health scores and inspector\n",
    "\n",
    "contingency_table = pd.crosstab(enc_df.inspector, enc_df.health_scores)\n",
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(contingency_table)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model- Binning based on probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a table to show the probability of inspectors assigning a certain health score\n",
    "\n",
    "contingency_table = pd.crosstab(df.inspector, df.health_scores, margins=True)\n",
    "contingency_table = contingency_table[contingency_table.All > 20]\n",
    "contingency_table['less_92'] = round(contingency_table['4']/contingency_table['All'],2)\n",
    "contingency_table['92_to_95'] = round(contingency_table['3']/contingency_table['All'],2)\n",
    "contingency_table['96_to_99'] = round(contingency_table['2']/contingency_table['All'],2)\n",
    "contingency_table['100'] = round(contingency_table['1']/contingency_table['All'],2)\n",
    "contingency_table.reset_index(inplace = True)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enc_df.merge(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[['name','review_count','rating','less_92','92_to_95','96_to_99','100', 'health_scores','sector_0', 'sector_1', 'sector_2', 'sector_3',\n",
    "       'sector_4', 'sector_5', 'sector_6', 'sector_7', 'sector_8', 'sector_9',\n",
    "       'sector_10', 'sector_11', 'sector_12', 'sector_13', 'sector_14',\n",
    "       'sector_15', 'sector_16', 'sector_17', 'sector_18', 'sector_19',\n",
    "       'sector_20', 'sector_21', 'sector_22', 'sector_23', 'sector_24',\n",
    "       'sector_25', 'sector_26', 'sector_27', 'sector_28', 'sector_29',\n",
    "       'sector_30', 'sector_31', 'sector_32', 'sector_33']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training / test split\n",
    "X= df.drop(columns=['name','health_scores'])\n",
    "y= df['health_scores']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 42, stratify=df.health_scores)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "\n",
    "#Create the Decision Tree Object\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state= 42, min_samples_split= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model to the training data\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate health group\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of a health group\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy: number of correct predictions over the number of total instances that have been evaluated.\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Model\n",
    "\n",
    "#Compute the accuracy of the model when run on the test data\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Random Forrest Model and setting the estimator to one million, because why not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "\n",
    "#Create the Random Forest Object\n",
    "#\n",
    "rf = RandomForestClassifier(max_depth=4, criterion='entropy', n_estimators=100000, random_state=42)\n",
    "#Fit the model to the training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the Feature importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of the health group, using the training data\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the accuracy of the model when run on the test data\n",
    "\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Confusion Matrix To Better Understand the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the confusion matrix \"pretty\"\n",
    "labels=(\" 100 \", \" 96-99 \", \" 92-95 \", \" <92 \")\n",
    "pretty_cm=pd.DataFrame(confusion_matrix(y_train,y_pred),index=labels,columns=labels)\n",
    "pretty_cm.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway: There is correlation between inspectors and the scores they give.\n",
    "### Further exploration is warranted. The distribution of missed predictions highlights one of the drawbacks to the model, which was the inconsistency of restaurant categorization of each individual restaurant in Yelp Fusion. Having the categories encoded and used as features would produce an improved model. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
